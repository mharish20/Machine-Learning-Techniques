{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "    TID                                               Item\n",
      "0    1     Lassi,Coffee Powder,Butter,Yougurt,Ghee,Cheese\n",
      "1    2                                 Ghee,Coffee Powder\n",
      "2    3                     Lassi,Tea Powder,Butter,Cheese\n",
      "3    4  Cheese,Tea Powder,Panner,Coffee Powder,Butter,...\n",
      "4    5    Cheese,Yougurt,Coffee Powder,Sugar,Butter,Sweet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Question 1: Load a dataset of transactions from a CSV file\n",
    "file_path = \"Shop2.csv\"  # Update this if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset Preview:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "      support                                          itemsets\n",
      "0       0.24                                           (Bread)\n",
      "1       0.56                                          (Butter)\n",
      "2       0.44                                          (Cheese)\n",
      "3       0.64                                   (Coffee Powder)\n",
      "4       0.44                                            (Ghee)\n",
      "..       ...                                               ...\n",
      "296     0.08            (Butter, Lassi, Yougurt, Panner, Milk)\n",
      "297     0.08       (Lassi, Panner, Ghee, Coffee Powder, Sugar)\n",
      "298     0.08       (Sweet, Lassi, Panner, Ghee, Coffee Powder)\n",
      "299     0.08  (Sweet, Lassi, Tea Powder, Coffee Powder, Sugar)\n",
      "300     0.08          (Sweet, Panner, Tea Powder, Ghee, Sugar)\n",
      "\n",
      "[301 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Convert transactions into a list of lists\n",
    "transactions = df[\"Item\"].apply(lambda x: x.split(\",\")).tolist()\n",
    "\n",
    "# Apply one-hot encoding\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Question 2: Identify frequent itemsets using the Apriori algorithm (Support threshold = 8%)\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.08, use_colnames=True)\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules:\n",
      "                     antecedents                  consequents  \\\n",
      "0                       (Bread)              (Coffee Powder)   \n",
      "1                       (Bread)                     (Panner)   \n",
      "2                       (Bread)                      (Sweet)   \n",
      "3                       (Bread)                 (Tea Powder)   \n",
      "4                      (Butter)                     (Cheese)   \n",
      "...                         ...                          ...   \n",
      "1008  (Sugar, Tea Powder, Ghee)              (Sweet, Panner)   \n",
      "1009              (Sweet, Ghee)  (Panner, Sugar, Tea Powder)   \n",
      "1010            (Panner, Sugar)    (Sweet, Tea Powder, Ghee)   \n",
      "1011         (Tea Powder, Ghee)       (Sweet, Panner, Sugar)   \n",
      "1012              (Sugar, Ghee)  (Sweet, Panner, Tea Powder)   \n",
      "\n",
      "      antecedent support  consequent support  support  confidence      lift  \\\n",
      "0                   0.24                0.64     0.20    0.833333  1.302083   \n",
      "1                   0.24                0.44     0.12    0.500000  1.136364   \n",
      "2                   0.24                0.44     0.12    0.500000  1.136364   \n",
      "3                   0.24                0.44     0.16    0.666667  1.515152   \n",
      "4                   0.56                0.44     0.32    0.571429  1.298701   \n",
      "...                  ...                 ...      ...         ...       ...   \n",
      "1008                0.08                0.20     0.08    1.000000  5.000000   \n",
      "1009                0.16                0.08     0.08    0.500000  6.250000   \n",
      "1010                0.16                0.08     0.08    0.500000  6.250000   \n",
      "1011                0.12                0.12     0.08    0.666667  5.555556   \n",
      "1012                0.12                0.12     0.08    0.666667  5.555556   \n",
      "\n",
      "      representativity  leverage  conviction  zhangs_metric   jaccard  \\\n",
      "0                  1.0    0.0464    2.160000       0.305263  0.294118   \n",
      "1                  1.0    0.0144    1.120000       0.157895  0.214286   \n",
      "2                  1.0    0.0144    1.120000       0.157895  0.214286   \n",
      "3                  1.0    0.0544    1.680000       0.447368  0.307692   \n",
      "4                  1.0    0.0736    1.306667       0.522727  0.470588   \n",
      "...                ...       ...         ...            ...       ...   \n",
      "1008               1.0    0.0640         inf       0.869565  0.400000   \n",
      "1009               1.0    0.0672    1.840000       1.000000  0.500000   \n",
      "1010               1.0    0.0672    1.840000       1.000000  0.500000   \n",
      "1011               1.0    0.0656    2.640000       0.931818  0.500000   \n",
      "1012               1.0    0.0656    2.640000       0.931818  0.500000   \n",
      "\n",
      "      certainty  kulczynski  \n",
      "0      0.537037    0.572917  \n",
      "1      0.107143    0.386364  \n",
      "2      0.107143    0.386364  \n",
      "3      0.404762    0.515152  \n",
      "4      0.234694    0.649351  \n",
      "...         ...         ...  \n",
      "1008   1.000000    0.700000  \n",
      "1009   0.456522    0.750000  \n",
      "1010   0.456522    0.750000  \n",
      "1011   0.621212    0.666667  \n",
      "1012   0.621212    0.666667  \n",
      "\n",
      "[1013 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Question 3: Generate association rules based on a minimum confidence threshold (50%)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# Display the generated association rules\n",
    "print(\"Association Rules:\\n\", rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Confidence Rules:\n",
      "                             antecedents           consequents  \\\n",
      "0                               (Bread)       (Coffee Powder)   \n",
      "5                              (Cheese)              (Butter)   \n",
      "10                              (Lassi)              (Butter)   \n",
      "11                               (Milk)              (Butter)   \n",
      "16                            (Yougurt)              (Butter)   \n",
      "...                                 ...                   ...   \n",
      "998   (Panner, Sugar, Tea Powder, Ghee)               (Sweet)   \n",
      "1002          (Sweet, Tea Powder, Ghee)       (Panner, Sugar)   \n",
      "1004               (Sweet, Sugar, Ghee)  (Panner, Tea Powder)   \n",
      "1006        (Panner, Sugar, Tea Powder)         (Sweet, Ghee)   \n",
      "1008          (Sugar, Tea Powder, Ghee)       (Sweet, Panner)   \n",
      "\n",
      "      antecedent support  consequent support  support  confidence      lift  \\\n",
      "0                   0.24                0.64     0.20    0.833333  1.302083   \n",
      "5                   0.44                0.56     0.32    0.727273  1.298701   \n",
      "10                  0.40                0.56     0.28    0.700000  1.250000   \n",
      "11                  0.32                0.56     0.24    0.750000  1.339286   \n",
      "16                  0.36                0.56     0.32    0.888889  1.587302   \n",
      "...                  ...                 ...      ...         ...       ...   \n",
      "998                 0.08                0.44     0.08    1.000000  2.272727   \n",
      "1002                0.08                0.16     0.08    1.000000  6.250000   \n",
      "1004                0.08                0.24     0.08    1.000000  4.166667   \n",
      "1006                0.08                0.16     0.08    1.000000  6.250000   \n",
      "1008                0.08                0.20     0.08    1.000000  5.000000   \n",
      "\n",
      "      representativity  leverage  conviction  zhangs_metric   jaccard  \\\n",
      "0                  1.0    0.0464    2.160000       0.305263  0.294118   \n",
      "5                  1.0    0.0736    1.613333       0.410714  0.470588   \n",
      "10                 1.0    0.0560    1.466667       0.333333  0.411765   \n",
      "11                 1.0    0.0608    1.760000       0.372549  0.375000   \n",
      "16                 1.0    0.1184    3.960000       0.578125  0.533333   \n",
      "...                ...       ...         ...            ...       ...   \n",
      "998                1.0    0.0448         inf       0.608696  0.181818   \n",
      "1002               1.0    0.0672         inf       0.913043  0.500000   \n",
      "1004               1.0    0.0608         inf       0.826087  0.333333   \n",
      "1006               1.0    0.0672         inf       0.913043  0.500000   \n",
      "1008               1.0    0.0640         inf       0.869565  0.400000   \n",
      "\n",
      "      certainty  kulczynski  \n",
      "0      0.537037    0.572917  \n",
      "5      0.380165    0.649351  \n",
      "10     0.318182    0.600000  \n",
      "11     0.431818    0.589286  \n",
      "16     0.747475    0.730159  \n",
      "...         ...         ...  \n",
      "998    1.000000    0.590909  \n",
      "1002   1.000000    0.750000  \n",
      "1004   1.000000    0.666667  \n",
      "1006   1.000000    0.750000  \n",
      "1008   1.000000    0.700000  \n",
      "\n",
      "[302 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Extract rules with higher confidence values (> 0.7)\n",
    "high_confidence_rules = rules[rules[\"confidence\"] > 0.7]\n",
    "\n",
    "# Display high-confidence association rules\n",
    "print(\"High Confidence Rules:\\n\", high_confidence_rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
